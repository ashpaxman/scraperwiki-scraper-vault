import scraperwiki
import lxml.html
a=[
'academyart.edu',
'afi.edu',
'american.edu',
'arizona.edu',
'artcenter.edu',
'asbury.edu',
'asu.edu',
'barnard.edu',
'bc.edu',
'berkeley.edu',
'bgsu.edu',
'bowdoin.edu',
'brandeis.edu',
'brown.edu',
'brynmawr.edu',
'bu.edu',
'buffalo.edu',
'byu.edu',
'calarts.edu',
'cca.edu',
'chapman.edu',
'cmu.edu',
'colorado.edu',
'colum.edu',
'columbia.edu',
'csulb.edu',
'csun.edu',
'cuny.edu',
'cwru.edu',
'dartmouth.edu',
'dickinson.edu',
'drexel.edu',
'du.edu',
'duke.edu',
'eckerd.edu',
'emory.edu',
'ewu.edu',
'fdu.edu',
'fsu.edu',
'fullsail.edu',
'gallaudet.edu',
'gsu.edu',
'gvsu.edu',
'harvard.edu',
'hofstra.edu',
'illinois.edu',
'indiana.edu',
'ithaca.edu',
'iub.edu',
'iupui.edu',
'jhu.edu',
'ku.edu',
'lacitycollege.edu',
'lafilm.edu',
'lindenwood.edu',
'lmu.edu',
'middlebury.edu',
'missouri.edu',
'montana.edu',
'msu.edu',
'mtholyoke.edu',
'ncsu.edu',
'nd.edu',
'newschool.edu',
'njcu.edu',
'nyfa.edu',
'nyu.edu',
'ohio.edu',
'osu.edu',
'ou.edu',
'pdx.edu',
'pitt.edu',
'psu.edu',
'purdue.edu',
'rice.edu',
'richmond.edu',
'rit.edu',
'rowan.edu',
'rutgers.edu',
'saic.edu',
'salisbury.edu',
'sc.edu',
'scad.edu',
'sdsu.edu',
'sfsu.edu',
'si.edu',
'siu.edu',
'smc.edu',
'smu.edu',
'sonoma.edu',
'sou.edu',
'stanford.edu',
'stjohns.edu',
'stolaf.edu',
'sunysb.edu',
'swarthmore.edu',
'syr.edu',
'tcu.edu',
'temple.edu',
'towson.edu',
'ua.edu',
'uaf.edu',
'uarts.edu',
'ucdavis.edu',
'ucf.edu',
'uchicago.edu',
'uci.edu',
'ucla.edu',
'ucmo.edu',
'ucsb.edu',
'ucsc.edu',
'uga.edu',
'umass.edu',
'umb.edu',
'umd.edu',
'umich.edu',
'umn.edu',
'uncw.edu',
'unlv.edu',
'unm.edu',
'unomaha.edu',
'unt.edu',
'uri.edu',
'usc.edu',
'usfca.edu',
'uta.edu',
'utah.edu',
'utexas.edu',
'utulsa.edu',
'uwm.edu',
'vanderbilt.edu',
'vassar.edu',
'vatican.edu',
'vcu.edu',
'vfs.edu',
'webster.edu',
'wesleyan.edu',
'wfu.edu',
'wisc.edu',
'wm.edu',
'wmich.edu',
'wustl.edu',
'yale.edu',
'yc.edu'
]
b=0
title=str
while b !=145: 
    html = scraperwiki.scrape("http://www."+str(a[b]))
    root = lxml.html.fromstring(html)
    for el in root.cssselect("title"):
        title=el.text
    scraperwiki.sqlite.save(unique_keys=['orden'],data={'orden':b,'title':title})
    title=""
    b=b+1


