This repository contains code for all public scrapers at scraperwiki.com, as of <br>04:56PM on September 30, 2013<br><br>It was created by pallih @ gogn.in / twitter.com/pallih<br><br>Some statistics: <br><br>Count of file extensions<br>Extension:  34<br>Extension: .php 2968<br>Extension: .tar 4189<br>Extension: .rb 2653<br>Extension: .py 14245<br>Extension: .txt 1<br>Extension: .html 529<br><br><br>User stats:<br><br>Number of users: 4189<br><br>Users with over 100 scrapers:<br>robksawyer 387<br>tlevine 243<br>buttub 231<br>frabcus 188<br>owl 172<br>ross 171<br>NicolaHughes 154<br>lostexpectation 150<br>psychemedia 147<br>pallih 138<br>paulbradshaw 137<br>aspeakman 136<br>pinakighosh 135<br>Toxicfly 130<br>DragonDave 121<br><br><br>Usernames that retrieval failed (at least partially) for:<br>raus81<br>ccbcreg<br>jnarra<br>Julian_Todd<br><br><br>Count of python module imports<br><br>peerreach 1<br>pylab 2<br>html.entities 2<br>tables 2<br>mmap 2<br>twisted.names 2<br>local 2<br>scrapy.utils 2<br>urllib.parse 2<br>selenium.webdriver.support.ui 2<br>jinja2 2<br>hotshot 2<br>nltk.tag 2<br>elementtidy 2<br>importlib 2<br>tweepy.streaming 2<br>rpy2.robjects.lib 2<br>zlib 2<br>stat 2<br>atexit 2<br>twill 2<br>msgpack 2<br>gdata.spreadsheet 2<br>colorsys 2<br>SpiderMonkey 2<br>email 2<br>GeoIP 2<br>twitter.oauth_dance 2<br>xml.etree 2<br>PIL 2<br>geopy.geocoders.google 2<br>PyQt4.QtGui 2<br>rpy2.robjects.packages 2<br>pdb 2<br>PyQt4.QtWebKit 2<br>scipy.stats 2<br>cld 2<br>robotparser 2<br>fom.session 2<br>gdata.docs 2<br>sitescraper 2<br>networkx.algorithms 2<br>twisted.web 2<br>pygments.formatters 2<br>Beautifulsoup 2<br>htmltable2matrix 2<br>pattern.search 2<br>repr 2<br>mimetools 2<br>freesteel.freesteelpy 2<br>suds 2<br>dateutil.tz 2<br>icalendar.cal 2<br>bz2 2<br>freesteel.savecontours 2<br>bs4.element 2<br>rpy2 2<br>getopt 2<br>config 2<br>PyQt4.QtCore 2<br>asynchat 2<br>pdfminer 2<br>readline 2<br>scrapy_utils 2<br>html.parser 2<br>lmx.html 2<br>twisted.internet 2<br>formatter 3<br>cartodb 4<br>pdfminer.cmapdb 4<br>smtplib 4<br>pattern.web 4<br>gdata.youtube.service 4<br>xlwt 4<br>pydot 4<br>Levenshtein 4<br>webscraping 4<br>twitter 4<br>scrapy.cmdline 4<br>struct 4<br>scrapely 4<br>matplotlib 4<br>scrapy.utils.misc 4<br>Image 4<br>doctest 4<br>ipdb 4<br>freesteel 4<br>unittest 4<br>nltk.metrics 4<br>community 4<br>scrapely.extraction 4<br>pygments 4<br>imp 4<br>nltk.book 4<br>twitter.oauth 4<br>pdftoxml 4<br>worker 4<br>email.utils 4<br>tidylib 4<br>scraper_utils 4<br>stdnum.isbn 4<br>shutil 4<br>gdata.youtube 4<br>mimetypes 4<br>urllib.request 4<br>textwrap 4<br>scrapely.htmlpage 4<br>hmac 4<br>googlemaps 6<br>functools 6<br>yaml 6<br>ckanclient 6<br>ssl 6<br>new 6<br>matplotlib.cbook 6<br>gdata.spreadsheet.service 6<br>pattern.en 6<br>inspect 6<br>nltk.collocations 6<br>commands 6<br>geopy.distance 6<br>xmltodict 6<br>gasp_helper 6<br>exceptions 6<br>getpass 6<br>lxml.builder 6<br>jellyfish 6<br>geopy.geocoders 6<br>scrapely.template 8<br>multiprocessing 8<br>matplotlib.ticker 8<br>timeit 8<br>warnings 8<br>pycurl 8<br>sets 8<br>pyPdf 8<br>pdfminer.pdfdevice 8<br>pattern.graph 8<br>pygments.lexers 8<br>argparse 8<br>w3lib.html 8<br>rfc822 9<br>optparse 10<br>gdata.docs.service 10<br>matplotlib.mlab 10<br>yql 10<br>contextlib 10<br>tarfile 12<br>networkx.readwrite 12<br>imposm.parser 12<br>bitlyapi 12<br>ClientForm 13<br>scipy 14<br>Queue 14<br>matplotlib.dates 14<br>twill.commands 14<br>gzip 14<br>selenium 16<br>xml.sax.saxutils 16<br>ast 16<br>glob 16<br>pyparsing 16<br>scraperwiki.geo 16<br>scrapy.spider 18<br>pdfminer.converter 18<br>pandas 18<br>cPickle 20<br>chardet 20<br>difflib 20<br>scraperwiki.utils 22<br>subprocess 22<br>oauth2 22<br>matplotlib.pyplot 22<br>dateutil.relativedelta 22<br>os.path 22<br>md5 23<br>xml.dom 23<br>htmllib 23<br>array 24<br>threading 25<br>pdfminer.pdfparser 26<br>pipe2py 28<br>pdfminer.layout 30<br>pdfminer.pdfinterp 32<br>pytz 35<br>rdflib 36<br>xml.etree.ElementTree 40<br>gc 42<br>turtle 42<br>nltk.corpus 42<br>openpyxl 42<br>html5lib 42<br>types 44<br>lxml.html.soupparser 44<br>xml.dom.minidom 44<br>nltk 44<br>scrapy.settings 45<br>networkx.readwrite.gexf 48<br>calendar 48<br>locale 48<br>unidecode 50<br>xml.etree.cElementTree 52<br>gviz_api 53<br>scraperwiki.metadata 54<br>pickle 54<br>HTMLParser 58<br>logging 59<br>scraperwiki.datastore 59<br>feedparser 62<br>cStringIO 62<br>decimal 63<br>zipfile 64<br>htmlentitydefs 66<br>traceback 69<br>copy 70<br>icalendar 70<br>scrapy.conf 72<br>hashlib 73<br>networkx 76<br>scrapy.http 79<br>codecs 80<br>numpy 80<br>tweepy 82<br>dateutil 92<br>demjson 98<br>scrapy.contrib.linkextractors.sgml 103<br>scrapy.contrib.loader 103<br>httplib2 112<br>operator 112<br>resource 114<br>scrapy.crawler 115<br>lxml.html.clean 116<br>socket 116<br>scrapy.selector 117<br>pyquery 121<br>uuid 123<br>pygooglechart 139<br>lxml.cssselect 141<br>collections 147<br>scrapy.xlib.pydispatch 160<br>sqlite3 161<br>httplib 170<br>unicodedata 174<br>base64 206<br>scrapy.contrib.spiders 206<br>scrapy.contrib.loader.processor 208<br>cookielib 226<br>scrapy.item 238<br>tempfile 240<br>itertools 263<br>math 269<br>scrapy 277<br>scrapemark 288<br>pprint 304<br>geopy 305<br>StringIO 312<br>cgi 361<br>xlrd 401<br>random 535<br>bs4 601<br>scraperwiki.sqlite 723<br>os 860<br>dateutil.parser 943<br>scraperwiki.apiwrapper 987<br>csv 1057<br>lxml 1063<br>string 1127<br>requests 1355<br>lxml.etree 1991<br>json 2062<br>sys 2140<br>urlparse 2257<br>mechanize 2300<br>time 2469<br>BeautifulSoup 3584<br>urllib 3867<br>datetime 5144<br>simplejson 5613<br>re 7120<br>urllib2 7700<br>lxml.html 10080<br>scraperwiki 25309<br>